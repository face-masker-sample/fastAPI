"""
ì‹¤ì‹œê°„ ì–¼êµ´ ë§ˆìŠ¤í‚¹ ì„œë¹„ìŠ¤
CCTV ìŠ¤íŠ¸ë¦¼ì—ì„œ ì–¼êµ´ì„ íƒì§€í•˜ê³  ë§ˆìŠ¤í‚¹ ì²˜ë¦¬í•˜ëŠ” í•µì‹¬ ì„œë¹„ìŠ¤
"""

import cv2
import numpy as np
import asyncio
import base64
import time
from datetime import datetime
from typing import AsyncGenerator, Optional, Dict, Any
from ultralytics import YOLO
from huggingface_hub import hf_hub_download
import logging

from app.core.config import settings

logger = logging.getLogger(__name__)

class FaceMaskingService:
    """ì‹¤ì‹œê°„ ì–¼êµ´ ë§ˆìŠ¤í‚¹ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self.model: Optional[YOLO] = None
        self.cap: Optional[cv2.VideoCapture] = None
        self.is_recording: bool = False
        self.video_writer: Optional[cv2.VideoWriter] = None
        self.stats = {
            "total_frames": 0,
            "total_faces_detected": 0,
            "average_fps": 0.0,
            "last_detection_time": None,
            "recording_status": False,
            "system_start_time": datetime.now().isoformat()
        }
        
    async def initialize(self):
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        logger.info("ğŸš€ ì–¼êµ´ ë§ˆìŠ¤í‚¹ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹œì‘")
        
        # YOLO ëª¨ë¸ ë¡œë“œ
        await self._load_model()
        
        # ì›¹ìº  ì´ˆê¸°í™”
        await self._setup_webcam()
        
        logger.info("âœ… ì–¼êµ´ ë§ˆìŠ¤í‚¹ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        
    async def _load_model(self):
        """YOLO ì–¼êµ´ íƒì§€ ëª¨ë¸ ë¡œë“œ"""
        try:
            logger.info("ğŸ¤– YOLOv8-Face ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...")
            model_path = hf_hub_download(
                repo_id=settings.YOLO_MODEL_REPO,
                filename=settings.YOLO_MODEL_FILE
            )
            self.model = YOLO(model_path)
            logger.info("âœ… YOLOv8-Face ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
            
        except Exception as e:
            logger.warning(f"âš ï¸ YOLOv8-Face ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            logger.info("ğŸ”„ ê¸°ë³¸ YOLO ëª¨ë¸ë¡œ ëŒ€ì²´")
            self.model = YOLO('yolov8n.pt')
            
    async def _setup_webcam(self):
        """ì›¹ìº  ì´ˆê¸°í™”"""
        try:
            self.cap = cv2.VideoCapture(settings.WEBCAM_INDEX)
            
            # ì›¹ìº  ì„¤ì •
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, settings.WEBCAM_WIDTH)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, settings.WEBCAM_HEIGHT)
            self.cap.set(cv2.CAP_PROP_FPS, settings.WEBCAM_FPS)
            
            if not self.cap.isOpened():
                raise Exception("ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                
            logger.info("ğŸ“¹ ì›¹ìº  ì´ˆê¸°í™” ì„±ê³µ")
            
        except Exception as e:
            logger.error(f"âŒ ì›¹ìº  ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
            
    def _create_smooth_blur(self, image: np.ndarray, x1: int, y1: int, x2: int, y2: int) -> np.ndarray:
        """ë¹ ë¥¸ ì´ëª¨ì§€ ë§ˆìŠ¤í‚¹ (ì„±ëŠ¥ ìµœì í™”)"""
        h, w = image.shape[:2]
        
        # ê²½ê³„ í™•ì¸
        x1, y1 = max(0, x1), max(0, y1)
        x2, y2 = min(w, x2), min(h, y2)
        
        if x2 <= x1 or y2 <= y1:
            return image
        
        # ì–¼êµ´ í¬ê¸° ê³„ì‚°
        face_w, face_h = x2 - x1, y2 - y1
        face_size = min(face_w, face_h)
        
        # ì´ëª¨ì§€ ì¤‘ì‹¬ì  ê³„ì‚°
        center_x = (x1 + x2) // 2
        center_y = (y1 + y2) // 2
        
        # ì´ëª¨ì§€ í¬ê¸° (ì–¼êµ´ë³´ë‹¤ ì•½ê°„ í¬ê²Œ)
        emoji_radius = int(face_size * 0.6)
        
        # ìŠ¤ë§ˆì¼ ì´ëª¨ì§€ ê·¸ë¦¬ê¸° (ë¹ ë¥¸ ë²„ì „)
        self._draw_fast_smile_emoji(image, center_x, center_y, emoji_radius)
        
        return image
    
    def _draw_fast_smile_emoji(self, image, center_x, center_y, radius):
        """ê³ ì† ìŠ¤ë§ˆì¼ ì´ëª¨ì§€ ê·¸ë¦¬ê¸°"""
        # ë…¸ë€ìƒ‰ ë°°ê²½ ì›
        cv2.circle(image, (center_x, center_y), radius, (0, 215, 255), -1)  # BGR: ë…¸ë€ìƒ‰
        
        # ê²€ì€ìƒ‰ í…Œë‘ë¦¬
        cv2.circle(image, (center_x, center_y), radius, (0, 0, 0), 3)
        
        # ëˆˆ ê·¸ë¦¬ê¸°
        eye_offset_x = radius // 3
        eye_offset_y = radius // 4
        eye_radius = radius // 8
        
        # ì™¼ìª½ ëˆˆ
        cv2.circle(image, (center_x - eye_offset_x, center_y - eye_offset_y), eye_radius, (0, 0, 0), -1)
        
        # ì˜¤ë¥¸ìª½ ëˆˆ
        cv2.circle(image, (center_x + eye_offset_x, center_y - eye_offset_y), eye_radius, (0, 0, 0), -1)
        
        # ì… ê·¸ë¦¬ê¸° (ìŠ¤ë§ˆì¼)
        mouth_y = center_y + radius // 4
        mouth_width = radius // 2
        mouth_height = radius // 3
        
        # ìŠ¤ë§ˆì¼ í˜¸ ê·¸ë¦¬ê¸°
        cv2.ellipse(image, (center_x, mouth_y), (mouth_width, mouth_height), 0, 0, 180, (0, 0, 0), 4)
        
    def _detect_faces(self, frame: np.ndarray) -> list:
        """ì–¼êµ´ íƒì§€"""
        if self.model is None:
            return []
            
        # ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ
        enhanced = cv2.bilateralFilter(frame, 9, 75, 75)
        
        # YOLO íƒì§€
        results = self.model(
            enhanced,
            conf=settings.FACE_CONFIDENCE_THRESHOLD,
            iou=settings.FACE_IOU_THRESHOLD,
            imgsz=settings.INPUT_IMAGE_SIZE,
            verbose=False
        )
        
        faces = []
        for result in results:
            if result.boxes is not None:
                for box in result.boxes:
                    conf = float(box.conf[0])
                    x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())
                    
                    # ìµœì†Œ í¬ê¸° ì²´í¬
                    w, h = x2 - x1, y2 - y1
                    if w >= 20 and h >= 20:  # 20x20 í”½ì…€ ì´ìƒ
                        faces.append((x1, y1, x2, y2, conf))
                        
        return faces
        
    async def get_masked_stream(self) -> AsyncGenerator[Dict[str, Any], None]:
        """ë§ˆìŠ¤í‚¹ëœ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¼ ì œê³µ"""
        if self.cap is None:
            logger.error("âŒ ì›¹ìº ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
            return
            
        fps_counter = 0
        start_time = time.time()
        
        while True:
            ret, frame = self.cap.read()
            if not ret:
                logger.warning("âš ï¸ ì›¹ìº ì—ì„œ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŒ")
                await asyncio.sleep(0.1)
                continue
                
            # ì¢Œìš° ë°˜ì „ (ê±°ìš¸ íš¨ê³¼)
            frame = cv2.flip(frame, 1)
            
            # ì–¼êµ´ íƒì§€
            faces = self._detect_faces(frame)
            
            # ì–¼êµ´ ë§ˆìŠ¤í‚¹
            for x1, y1, x2, y2, conf in faces:
                frame = self._create_smooth_blur(frame, x1, y1, x2, y2)
                
            # ë…¹í™” ì¤‘ì´ë©´ ë¹„ë””ì˜¤ íŒŒì¼ì— ì €ì¥
            if self.is_recording and self.video_writer is not None:
                self.video_writer.write(frame)
                
            # FPS ê³„ì‚°
            fps_counter += 1
            elapsed = time.time() - start_time
            if elapsed >= 1.0:
                current_fps = fps_counter / elapsed
                self.stats["average_fps"] = current_fps
                fps_counter = 0
                start_time = time.time()
            else:
                current_fps = self.stats["average_fps"]
                
            # í†µê³„ ì—…ë°ì´íŠ¸
            self.stats["total_frames"] += 1
            self.stats["total_faces_detected"] += len(faces)
            if len(faces) > 0:
                self.stats["last_detection_time"] = datetime.now().isoformat()
                
            # ì •ë³´ í‘œì‹œ
            info_text = f'FPS: {current_fps:.1f} | Faces: {len(faces)}'
            if self.is_recording:
                info_text += " | REC"
                
            cv2.putText(frame, info_text, (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                       
            # í”„ë ˆì„ì„ JPEGë¡œ ì¸ì½”ë”© (ì„±ëŠ¥ ìµœì í™”)
            encode_params = [
                cv2.IMWRITE_JPEG_QUALITY, settings.STREAM_QUALITY,
                cv2.IMWRITE_JPEG_OPTIMIZE, 1  # JPEG ìµœì í™” í™œì„±í™”
            ]
            _, buffer = cv2.imencode('.jpg', frame, encode_params)
            frame_base64 = base64.b64encode(buffer).decode('utf-8')
            
            # ë°ì´í„° ë°˜í™˜
            yield {
                "frame": frame_base64,
                "faces_count": len(faces),
                "fps": current_fps,
                "timestamp": datetime.now().isoformat(),
                "recording": self.is_recording
            }
            
            # FPS ì¡°ì ˆ
            await asyncio.sleep(1.0 / settings.STREAM_FPS)
            
    async def start_recording(self) -> bool:
        """ë…¹í™” ì‹œì‘"""
        if self.is_recording:
            logger.warning("âš ï¸ ì´ë¯¸ ë…¹í™” ì¤‘ì…ë‹ˆë‹¤")
            return False
            
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{settings.RECORDING_DIR}/recording_{timestamp}.mp4"
            
            fourcc = cv2.VideoWriter_fourcc(*settings.RECORDING_FORMAT)
            self.video_writer = cv2.VideoWriter(
                filename, fourcc, settings.STREAM_FPS, 
                (settings.WEBCAM_WIDTH, settings.WEBCAM_HEIGHT)
            )
            
            self.is_recording = True
            self.stats["recording_status"] = True
            logger.info(f"ğŸ¬ ë…¹í™” ì‹œì‘: {filename}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë…¹í™” ì‹œì‘ ì‹¤íŒ¨: {e}")
            return False
            
    async def stop_recording(self) -> bool:
        """ë…¹í™” ì¤‘ì§€"""
        if not self.is_recording:
            logger.warning("âš ï¸ ë…¹í™” ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤")
            return False
            
        try:
            self.is_recording = False
            self.stats["recording_status"] = False
            
            if self.video_writer is not None:
                self.video_writer.release()
                self.video_writer = None
                
            logger.info("ğŸ›‘ ë…¹í™” ì¤‘ì§€ë¨")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë…¹í™” ì¤‘ì§€ ì‹¤íŒ¨: {e}")
            return False
            
    async def take_screenshot(self) -> Optional[str]:
        """ìŠ¤í¬ë¦°ìƒ· ì´¬ì˜"""
        if self.cap is None:
            return None
            
        try:
            ret, frame = self.cap.read()
            if not ret:
                return None
                
            # ì¢Œìš° ë°˜ì „
            frame = cv2.flip(frame, 1)
            
            # ì–¼êµ´ íƒì§€ ë° ë§ˆìŠ¤í‚¹
            faces = self._detect_faces(frame)
            for x1, y1, x2, y2, conf in faces:
                frame = self._create_smooth_blur(frame, x1, y1, x2, y2)
                
            # íŒŒì¼ ì €ì¥
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{settings.SCREENSHOT_DIR}/screenshot_{timestamp}.jpg"
            
            cv2.imwrite(filename, frame)
            logger.info(f"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {filename}")
            return filename
            
        except Exception as e:
            logger.error(f"âŒ ìŠ¤í¬ë¦°ìƒ· ì‹¤íŒ¨: {e}")
            return None
            
    async def get_statistics(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ í†µê³„ ë°˜í™˜"""
        return self.stats.copy()
        
    async def cleanup(self):
        """ì„œë¹„ìŠ¤ ì •ë¦¬"""
        logger.info("ğŸ§¹ ì–¼êµ´ ë§ˆìŠ¤í‚¹ ì„œë¹„ìŠ¤ ì •ë¦¬ ì‹œì‘")
        
        # ë…¹í™” ì¤‘ì§€
        if self.is_recording:
            await self.stop_recording()
            
        # ì›¹ìº  í•´ì œ
        if self.cap is not None:
            self.cap.release()
            self.cap = None
            
        logger.info("âœ… ì–¼êµ´ ë§ˆìŠ¤í‚¹ ì„œë¹„ìŠ¤ ì •ë¦¬ ì™„ë£Œ") 